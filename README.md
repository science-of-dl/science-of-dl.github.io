# Sudo Science: Building an Empirical Understanding of Deep Learning

## Tentative Workshop Schedule (times ET)


| Time    	| Speaker/ Activity   	     | 
|---------	|-----------	     |
| 8:30am-9:00am 	| Informal Social Coffee	     | 
| 9:00am-9:45am    | Talk 1 (Behnam Neyshabur) and Q&A | 
|10:00am-10:45am |  Talk 2 (Polina Kirichenko) and Q&A |
| 11:00am-11:45am |Talk 3 (Yann Lecun & Randall Balestriero) and Q&A |
| 11:45pm-12:30pm| Lunch Break |
| 12:30pm-1:30pm |Panel Discussion* |
|1:30pm-2:15pm | Talk 4 (SueYeon Chung) and Q&A |
|2:30pm-3:15pm |Talk 5 (Maithra Raghu) and Q&A |
|3:15pm-4:00pm | Casual Breakout Discussion Session |
|4:00pm-4:45pm | Talk 6 (Preetum Nakkiran) and Q&A |
|5:00pm-6:00pm | Poster Session | 

***Panel members - Preetum Nakkiran, Anima Anandkumar, Yasaman Bahri, Shibani Santurkar, Behnam Neyshabur, SueYeon Chung**

----

Despite the widespread proliferation of neural networks, the mechanisms by which they operate so successfully are not well understood.  While there is a strong community that seeks to understand training and generalization, this work is largely done by developing fundamental mathematical theory. These theories often rely on strong assumptions and significantly simplified setups that admit tractable mathematical analysis, but have the unintended consequence of also paring away complexities of deep learning pipelines that may be responsible for their success.  At the same time, there is a large community focused on experimental studies of full-scale deep learning systems, but nearly all empirical studies are focused on applied science — fine-tuning, and improving benchmark numbers. Meanwhile, the deep learning community has had trouble creating a home for fundamental science, i.e, empirical studies that seek to understand the phenomena that underlie training and generalization using the scientific method without resorting to highly simplified toy models.  Fundamental empirical studies risk rejection by the deeply mathematical fundamental ML community because they do not contain proofs, and simultaneously fail to appeal to the applied science community because they do not advance conventional engineering benchmarks.  

The goal of this workshop is to be a home for fundamental studies that use empirical science to examine the inner workings of the full-fledged neural network systems that are used in practice.  This focus will be reflected through invited talks as well as a panel discussion comprising theorists, neuroscientists, and empirical ML researchers who will discuss the roles of each approach in developing an understanding of deep learning.  Topics of focus will include (1) what phenomena have recently been demonstrated in empirical studies, but for which we do not yet have a theoretical understanding? (2) Do rigorous theories stand up to the test of sudo science, or do they fail to describe the behaviors, inputs, and training loops required for deep learning in practice? (3) What standards should be applied to fundamental experimental work in deep learning, and what is the role of reproducibility? If you have any questions, please reach out to Micah Goldblum (<goldblum@nyu.edu>) or this email (<scienceofdl@gmail.com>).


## Invited Speakers

**[SueYeon Chung](),** _Assistant Professor at New York University, Project Leader at Flatiron Institute_.
>SueYeon is an assistant Professor in the Center for Neural Science at NYU,  jointly appointed as a Project Leader at the Flatiron Institute, Simons Foundation. SueYeon’s research interests are at the intersection of computational neuroscience and deep learning. She is interested in understanding computation in the brain and artificial neural networks by analyzing geometries underlying neural or feature representations and developing neural network models and learning rules guided by neuroscience.

**[Polina Kirichenko](),** _PhD student at New York University_.
>Polina’s research focuses on deep learning robustness, uncertainty estimation and generative models. During her PhD, she interned at Meta AI, DeepMind, and Cold Spring Harbor Laboratory. In 2020, she was supported by the DeepMind fellowship.
**[Preetum Nakkiran](),** _Postdoctoral Researcher at UCSD, member of NSF/Simons Collaboration on the Theoretical Foundations of Deep Learning_.
>Preetum’s research builds conceptual tools for understanding learning systems, including deep learning--- using both theory and experiment. His past works include Deep Double Descent, the Deep Bootstrap Framework, and Distributional Generalization.

**[Anima Anandkumar](),** _Professor at California Institute of Technology, Director of ML, NVIDIA_.
>Anima is the Bren Professor of Computing at California Institute of Technology. She is a director of Machine Learning research at NVIDIA. Her research considers tensor-algebraic methods, deep learning, and non-convex problems.

**[Yann Lecun](),** _Silver Professor at Courant Institute, Vice President and Chief AI Scientist at Meta_.
> Yann’s current interests include AI, machine learning, computer perception, mobile robotics, and computational neuroscience. 

**[Yasaman Bahri](),** _Research Scientist at Google Research_.
>Yasaman is a theoretical and computational scientist working at the intersection of machine learning and physical science. In one direction, she has worked on building foundations for deep learning and investigated core machine learning problems. In the other, she is interested in connections with and applications of machine learning to specific domains of physical science.

**[Shibani Santurkar](),** _Postdoctoral Researcher at Stanford University_.
>Shibani works with Tatsu Hashimoto, Percy Liang, and Tengyu Ma, developing machine learning tools that can perform reliably in the real world, and characterizing the consequences if they fail to do so. Shibani’s research is supported by Open Philanthropy.

**[Maithra Raghu]()** _Senior Research Scientist at Google Brain_.
>Maithra’s research focuses on enabling better interfacing between humans and AI systems, through developing techniques that give insights into the internals of modern machine learning systems, and using these insights to inform their design and interaction with humans at deployment.

**[Behnam Neyshabur]()** _Senior Staff Research Scientist at Google_.
>Behnam is a senior staff research scientist at Google. Before that, he was a postdoctoral researcher at New York University and a member of Theoretical Machine Learning program at Institute for Advanced Study (IAS) in Princeton. Behnam’s interests include the science of deep learning and (out-of-distribution) generalization, where he has studied the role of implicit bias as well as compression-based notions of generalization.


## Organizers

**Micah Goldblum,** _New York University, Main Coordinator_.
> Micah Goldblum is a postdoctoral researcher at the Center for Data Science at NYU.  His research focus lies at the intersection of machine learning and optimization with the aim of creating practical systems that are secure, efficient, and reliable on real-world problems and understanding how such systems work. His current work focuses on understanding the mechanisms of data augmentation, transfer learning, and compressibility-based notions of generalization.  Micah was the chair of the organizing committee for the NeurIPS 2020 Workshop on Dataset Curation and Security.

**Tom Goldstein,** _University of Maryland, College Park_.
>Tom Goldstein is the Perotto Associate Professor of Computer Science at the University of Maryland.  His research lies at the intersection of machine learning and optimization, and targets applications in computer vision and signal processing. Before joining the faculty at Maryland, Tom completed his PhD in Mathematics at UCLA, and was a research scientist at Rice University and Stanford University. Professor Goldstein has been the recipient of several awards, including SIAM’s DiPrima Prize, a DARPA Young Faculty Award, a JP Morgan Faculty award, and a Sloan Fellowship.

**Andrew Gordon Wilson**, _New York University_.
>Andrew is an Associate Professor in the Courant Institute of Mathematical Sciences and Center for Data Science at New York University. His work is focused on developing a prescriptive understanding of model construction and generalization, often working with probabilistic and Bayesian methods involving deep neural networks and Gaussian processes. He has organized over 10 highly successful workshops across NeurIPS and ICML, including a major NeurIPS 2017 symposium on interpretable machine learning. Andrew also co-organized the NeurIPS 2021 competition for approximate inference in Bayesian deep learning, has been the EXPO Chair for ICML 2020, 2021, and is the Tutorial Chair for NeurIPS 2022.

**Sanae Lotfi,** _New York University_.
> Sanae is a PhD student at the Center for Data Science at NYU and a DeepMind fellow, working with Professor Andrew Gordon Wilson. She is currently interested in understanding and quantifying the generalization of deep learning models. Her latest work focuses on understanding the failure modes of Bayesian deep learning under distribution shift and the limits of the marginal likelihood in predicting generalization. Before joining NYU, Sanae obtained a master’s degree in applied mathematics from Polytechnique Montreal where she focused on designing stochastic first and second order algorithms with compelling theoretical and empirical properties for machine learning. Sanae co-organized the NeurIPS 2021 Approximate Inference in Bayesian Deep Learning competition. 

**Gowthami Somepalli,** _University of Maryland, College Park_.
> Gowthami is a Ph.D. student in the Department of Computer Science at the University of Maryland, College Park. Her research is mainly focused on building both theoretical and empirical tools to understand deep learning models, especially for various Computer Vision tasks. Before starting her Ph.D., she worked in industry in various product and engineering roles and received her bachelors from IIT Madras. She is also the recipient of 2021 Kulkarni Fellowship.

**Jonas Geiping,** _University of Maryland, College Park_.
> Jonas is a postdoctoral researcher at the University of Maryland, College Park. His research is centered on the intersection of current deep learning and mathematical optimization. As such, recent work has included understanding the impact of optimization on fundamental phenomena behind generalization and other topics in empirical investigation of deep learning phenomena. Jonas was awarded a PhD by the University of Siegen in 2021. He has previously co-organized the workshop  “Imaging and Vision from Theory to Applications”.


